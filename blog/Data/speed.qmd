---
title: "Testing Python vs R"
date: "2025-06-07"
date-format: medium
categories: [R, Python, Tutorial]
tags: [Data, R Programming, Python]
toc: true
image: speed.png
---

```{python}
#| label: Python set up
#| echo: false

import polars as pl
from ttictoc import tic,toc
import time
import pandas as pd
import timeit
```

```{r}
#| label: R set up
#| echo: false
#| message: false
#| warning: false

if(!require("pacman"))install.packages("pacman")
pacman::p_load(readr,dplyr,polars,tidypolars,tictoc,reticulate,data.table,quarto,bench)
use_virtualenv(here::here(".venv"))
```

```{r}
#| echo: false

nba_dim <- dim(read.csv("nba_all_elo.csv"))
a <- sessionInfo()
```

As data analysts and researchers, we often toggle between R and Python. But how do they compare in terms of raw speed—especially for common tasks like grouped aggregation?

In this post, I benchmark different approaches using both R and Python, including base R, tidyverse, data.table, pandas, and polars. I also experiment with calling Python's Polars from within R using reticulate, just to see if inter-language calls come with performance penalties—or surprises.

Let’s dive in.

## The Setup
The dataset I’m using is `nba_all_elo.csv`. You can get the data [here]("https://raw.githubusercontent.com/fivethirtyeight/data/master/nba-elo/nbaallelo.csv") It contains Elo ratings and predictions for thousands of NBA games. This data has `r nba_dim[1]` rows and `r nba_dim[2]` columns. 


::: {.panel-tabset}
## Base- R

```{r}
bench::mark(
  base_r = {
    nba <- read.csv("nba_all_elo.csv")
    aggregate(forecast ~ game_result, data = nba, FUN = mean)
  },
  iterations = 10,
  check = FALSE
)
```

## R - Tidyverse
```{r}
#| message: false
#| warning: false

bench::mark(
  tidyverse = {
    read_csv("nba_all_elo.csv") |>
      summarise(avg_points = mean(forecast), .by = game_result)
  },
  iterations = 10,
  check = FALSE
)
```

## Python - Polars

```{python}
polars_stmt = """
import polars as pl
df = pl.read_csv('nba_all_elo.csv')
df.group_by('game_result').agg(pl.col('forecast').mean().alias('avg_points'))
"""
polars_time = timeit.timeit(stmt=polars_stmt, number=10) / 10
print(f"Polars avg time over 10 runs: {polars_time:.6f} sec")
```

## Python - Pandas

```{python}
pandas_stmt = """
import pandas as pd
df = pd.read_csv('nba_all_elo.csv')
df.groupby('game_result', as_index=False)["forecast"].mean()
"""
pandas_time = timeit.timeit(stmt=pandas_stmt, number=10) / 10
print(f"Pandas avg time over 10 runs: {pandas_time:.6f} sec")
```

## Polars in R

```{r}
bench::mark(
  r_polars = {
    df <- pl$read_csv("nba_all_elo.csv")
    df$group_by("game_result")$agg(
      pl$col("forecast")$mean()$alias("avg_points")
    )
  },
  iterations = 10,
  check = FALSE
)
```

## Polars inside R

```{r}
bench::mark(
  py_polars_in_r = {
    py_run_string(
      "
import polars as pl
df = pl.read_csv('nba_all_elo.csv')
df.group_by('game_result').agg(
  pl.col('forecast').mean().alias('avg_points')
)
      "
    )
  },
  iterations = 10,
  check = FALSE
)
```

## R - data.table
```{r}
bench::mark(
  data_table = {
    dt <- fread("nba_all_elo.csv")
    dt[, .(avg_points = mean(forecast, na.rm = TRUE)), by = game_result]
  },
  iterations = 10,
  check = FALSE
)
```

:::

## Key Takeaways
Here’s what stood out from the benchmarks:

✅ Polars in R is the fastest option available.  `data.table` is fast option but often comes at the cost of syntax which I am not comfortable with. It comfortably outsmarts both base R and the tidyverse.

✅ Polars is blazingly fast often 5–10x faster than Pandas or Tidyverse.

✅ Surprise! When I invoked Python’s Polars from within R via reticulate, it was as fast as running the same code directly in Python. 

## Final Thoughts
So, if performance is your priority:

- Use Polars in R.

- Use polars in Python—or even inside R if you’re already mixing languages.

- Avoid tidyverse for speed-critical tasks, unless readability is your goal.

 With tools like reticulate and quarto, we can blend strengths across ecosystems—without giving up speed. These tools help us to get the best of both worlds.

This document was built with R version `r getRversion()` and Python version `r py_config()$version`.

:::{.callout-tip collapse="true"}
# Session Info
## R
```{r, echo = FALSE}
library(sessioninfo)
# save the session info as an object
pkg_sesh <- session_info(pkgs = "attached")

# get the quarto version
quarto_version <- system("quarto --version", intern = TRUE)

# inject the quarto info
pkg_sesh$platform$quarto <- paste(
  system("quarto --version", intern = TRUE),
  "@",
  quarto::quarto_path()
)

# print it out
pkg_sesh
```

## Python

```{python}
#| echo: false
print("pandas:", pd.__version__)
print("polars:", pl.__version__)

```

:::

